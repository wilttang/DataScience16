{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 10\n",
    "\n",
    "This notebook is designed to cover some of the requests from [this](https://piazza.com/class/iju1ffuooio7mp?cid=28) Piazza post.\n",
    "\n",
    "High-level contents of this notebook:\n",
    "1.  Visualizing models\n",
    "2.  Determining when to use a particular model\n",
    "3.  Interpreting log-loss error metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be using both the Rotten Tomatoes and the SF Crime datasets as running examples.  This notebook assumes that you have downloaded the data for these contests from Kaggle and stored them in the directories indicated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tomatoes = pd.read_csv('../../datasets/rotten_tomatoes_train.tsv', sep='\\t')\n",
    "crime = pd.read_csv('../../datasets/sfcrime_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tomatoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization\n",
    "\n",
    "After you fit a model, you can compute the accuracy of your model by using the `model.score` function.  This will give you back a single number that indicates the quality of the model.  However, this in and of itself may not be terribly useful.\n",
    "\n",
    "Suppose, you tried a new model and the performance went up.  What phenomena in the data might be driving this change in performance?  Suppose, you actually want to use the machine learning model as a way to gain greater insight into the data.  How can you inspect the model to better understand the relationships between the variables within?\n",
    "\n",
    "This brings us to the topic of model visualization (also called model introspection).  In the next two sections we will be doing model visualization for two types of models: logistic regression models and decision tree models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section we will use the Rotten Tomatoes dataset.  The specific encoding of text to features that we will be using is [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).  You will recall that we built our own TF-IDF vectorizer in class last week.  Here, we will be using the vectorizer built into scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(tomatoes.Phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand what we just did let's take a look at the list of features names for this vectorizer.  These feature names are a list that shows us which column in the TF-IDF output corresponds to which word.  To avoid producing too much output, let's just look at a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[1000:1020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we transform the individual phrases using our vectorizer, create a train test split, and fit a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = vectorizer.transform(tomatoes.Phrase)\n",
    "y = tomatoes.Sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "model = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll visualize the learned model using a wordcloud.  First, install the wordcloud generator using pip install.\n",
    "\n",
    "`pip install wordcloud`\n",
    "\n",
    "Typically, a word cloud shows words scaled by their frequency in a document.  Here, we will be using the weights learned by our logistic regression model to scale the size of the words.  You can understand these visuals to make words larger if they have a *greater positive contribution to predicting a particular sentiment value*.\n",
    "\n",
    "Before we do this, let's take a look at our logistic regression model in more detail so we can understand more what's going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"coefficients\", model.coef_\n",
    "print \"coefficients.shape\", model.coef_.shape\n",
    "print \"intercepts\", model.intercept_\n",
    "print \"intercepts.shape\", model.intercept_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "print \"model probs\", model.predict_proba(X_test[0,:])\n",
    "linear = model.coef_.dot(X_test[0,:].todense().T) + model.intercept_[:,np.newaxis]\n",
    "print \"calculated probs\", np.exp(linear) / np.sum(np.exp(linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've built up some intuition for `model.coef_`, let's visualize these coefficients using a wordcloud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "\n",
    "def make_word_cloud(feature_names, coefficients):\n",
    "    \"\"\" Create a word cloud with the words given by feature_names\n",
    "        and given coefficients. \"\"\"\n",
    "    cloud = wordcloud.WordCloud()\n",
    "    cloud.generate_from_frequencies(zip(feature_names, coefficients))\n",
    "    return cloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word cloud for sentiment value 0 (worst possible)\n",
    "make_word_cloud(vectorizer.get_feature_names(), model.coef_[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word cloud for sentiment value 1\n",
    "make_word_cloud(vectorizer.get_feature_names(), model.coef_[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word cloud for sentiment value 2\n",
    "make_word_cloud(vectorizer.get_feature_names(), model.coef_[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word cloud for sentiment value 3\n",
    "make_word_cloud(vectorizer.get_feature_names(), model.coef_[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Word cloud for sentiment value 4 (best possible)\n",
    "make_word_cloud(vectorizer.get_feature_names(), model.coef_[4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Logistic Regression Model for SF Crime\n",
    "\n",
    "Next, we'll do a quick spin through the SF Crime dataset to see another example of visualizing a learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_crime = pd.get_dummies(crime.DayOfWeek)\n",
    "y_crime = crime.Category\n",
    "\n",
    "X_crime_train, X_crime_test, y_crime_train, y_crime_test = \\\n",
    "    train_test_split(X_crime, y_crime, train_size=.05)\n",
    "model_crime = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "model_crime.fit(X_crime_train, y_crime_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.plt.figure(figsize=(8,8))\n",
    "model_crime.classes_\n",
    "sns.heatmap(model_crime.coef_,\n",
    "            xticklabels=X_crime.columns,\n",
    "            yticklabels=model_crime.classes_)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Decision Tree\n",
    "\n",
    "Next, we will build a decision tree and use it to visualize the data.  In order to make the visualization tractable, we will make the decision tree relatively small.  However, there are lots of folks that are thinking about how to visualize larger decision trees (even random forests which combine multiple decision trees).  One of these students is our own Michael Bocamazo.  He's on leave doing an LOA, but maybe he'll be willing to provide suggestions down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth=4)\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to visualize a decision tree is to simply visualize the individual nodes in the tree graphically.  For small trees this exhaustive approach can work.  We will use the popular library graphviz to do this visualization.  Sklearn has a built in converter from the DecisionTree class to a graphviz dot file.  We will then use some ipython magic to render the graph in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_graphviz(tree_model, feature_names=vectorizer.get_feature_names(), out_file='tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%install_ext https://raw.github.com/cjdrake/ipython-magic/master/gvmagic.py\n",
    "%load_ext gvmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('tree.dot')\n",
    "tree_model_visualization = f.read()\n",
    "f.close()\n",
    "%dotstr tree_model_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the first node we are essentially using and as a proxy for a long phrase.  Long phrases are more likely to have polarized sentiment values.  Instead of making the algorithm do the work using TF-IDF, we can instead encode that feature directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "num_words_feature = np.asarray(map(lambda x: len(x.split()), tomatoes.Phrase))\n",
    "num_words_feature = num_words_feature[:, np.newaxis]\n",
    "X_with_num_words = sparse.hstack((X, num_words_feature))\n",
    "print X_with_num_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_model_with_num_words = DecisionTreeClassifier(max_depth=4)\n",
    "tree_model_with_num_words.fit(X_with_num_words, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_graphviz(tree_model_with_num_words,\n",
    "                feature_names=vectorizer.get_feature_names() + ['num_words'],\n",
    "                out_file='tree.dot')\n",
    "f = open('tree.dot')\n",
    "tree_model_visualization = f.read()\n",
    "f.close()\n",
    "%dotstr tree_model_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been good to visualize what is going on with the decision tree, but let's see how well we can do if we don't limit the depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_with_num_words, y, train_size=0.5)\n",
    "tree_model_with_num_words = DecisionTreeClassifier()\n",
    "tree_model_with_num_words.fit(X_train, y_train)\n",
    "tree_model_with_num_words.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how good we can do with a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_model_with_num_words = RandomForestClassifier()\n",
    "forest_model_with_num_words.fit(X_train, y_train)\n",
    "forest_model_with_num_words.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gained some insight that lead us to add a feature consisting of the number of words in the phrase, let's see if that boosts our score using logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "model.fit(X_train, y_train)\n",
    "print \"With num words\", model.score(X_test, y_test)\n",
    "\n",
    "model_without_num_words = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "model_without_num_words.fit(X_train[:,:-1], y_train)\n",
    "print \"Without num words\", model_without_num_words.score(X_test[:,:-1], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, let's tune the amount of regularization for our logistic regression model (since it seems to be working the best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "model = LogisticRegressionCV(Cs=[math.e**v for v in range(-5,5)],\n",
    "                             multi_class='multinomial',\n",
    "                             solver='newton-cg')\n",
    "model.fit(X_train, y_train)\n",
    "print \"With tuning\", model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Give Up on a Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are decision trees generally bad for sentiment analysis?  Let's plot the probability of some sentiment value versus the TF-IDF value for a particular word.  We'll deliberately pick a word that is likely to play an important role in determining the sentiment of a movie review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_log_odds_plot(word, sentiment):\n",
    "    log_odds = []\n",
    "    word_index = vectorizer.get_feature_names().index(word)\n",
    "    word_tf_idf = np.asarray(X_train[:,word_index].todense())\n",
    "    bucket_centers = np.arange(0, np.max(word_tf_idf), .1)\n",
    "    bucket_indices = np.digitize(word_tf_idf, bucket_centers)\n",
    "\n",
    "    for i, v in enumerate(bucket_centers):\n",
    "        smoothed_prob = np.sum((y_train[:, np.newaxis] == sentiment) * (bucket_indices == i)) / float(sum(bucket_indices == i))\n",
    "        log_odds.append(np.log(smoothed_prob / (1-smoothed_prob)))\n",
    "    plt.plot(bucket_centers, log_odds)\n",
    "    plt.ylabel('log odds ratio sentiment %d' % (sentiment,))\n",
    "    plt.xlabel('TF-IDF')\n",
    "\n",
    "make_log_odds_plot('good', 0)\n",
    "make_log_odds_plot('bad', 0)\n",
    "plt.legend(['good', 'bad'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_log_odds_plot('good', 4)\n",
    "make_log_odds_plot('bad', 4)\n",
    "plt.legend(['good', 'bad'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis we see that the there is a strong relationship between the magnitude of a TF-IDF feature and the resultant probability of the phrase having a certain sentiment value.  Why might this be hard for a tree to model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Log Loss\n",
    "\n",
    "One complexity of the SF Crime data is that it uses a metric other than accuracy.  This metric is called log loss.  Next, we will take a closer look at that error metric and some issues that arise in interpreting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_crimes = set(crime.Category)\n",
    "crime_probabilities = {}\n",
    "for c in all_crimes:\n",
    "    crime_probabilities[c] = (crime.Category == c).sum() / float(len(crime.Category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crime_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating a classifier according to log loss, we require the model to provide a probability of each possible outcome.  The model then incurs a loss proportional to the negative of the log of the probability the model assigned to that outcome.\n",
    "\n",
    "As an example, suppose the TV weather person assigned a probability of 0.7 to it raining and 0.2 it snowing and 0.1 to neither.  It turned out it snowed.  What is the log loss for this prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Sensible Baseline\n",
    "\n",
    "When we did the titanic dataset, the easiest baseline model was to simply predict that everyone perished (since it was the most common outcome).  Similarly, here we could predict 'OTHER-OFFENSES' for every data point.  However, we must do more than simply predict a single outcome, we must output a probability for each of the possible crimes.  The first thing to try is to output a probability of 1 for 'OTHER-OFFENSES' and 0 for all other crimes.  What will go wrong here?  Note: Kaggle saves you from this without really telling you that it is doing so.\n",
    "\n",
    "To improve upon this approach, we can simply predict the probabilities observed in the entire dataset for each individual datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline(x):\n",
    "    \"\"\" the baseline model ignores x and simply predicts the baseline probabilities\n",
    "        in the dataset \"\"\"\n",
    "    return crime_probabilities\n",
    "\n",
    "# this is super slow, and not recommended, but I wanted to illustrate the point clearly\n",
    "ll = 0.0\n",
    "for row in crime.iterrows():\n",
    "    # let's just use the X and Y position\n",
    "    features = np.asarray([row[1].X, row[1].Y])\n",
    "    probs = baseline(features)\n",
    "    ll += -np.log(probs[row[1].Category]) / float(len(crime))\n",
    "    if row[0] % 50000 == 0:\n",
    "        print row[0]/ float(len(crime))\n",
    "\n",
    "print \"log_loss\", ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is horribly slow, but luckily we can do a lot better.  You'll notice that we always add the same value for log_loss for a particular category.  To speed things up we can loop over crime categories and multiply the log loss by the count of the number of times it appears in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll = 0.0\n",
    "for category in all_crimes:\n",
    "    # baseline ignores x, so we just pass in None\n",
    "    probs = baseline(None)\n",
    "    ll += -np.log(probs[category])*(crime.Category == category).sum() / float(len(crime))\n",
    "\n",
    "print \"log_loss\", ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look a little closer, we will see that the second part of the expression in the loop is really just the probability of a crime in the dataset.  This let's us rewrite our code in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll = 0.0\n",
    "for category, prob in crime_probabilities.items():\n",
    "    ll += -np.log(prob)*prob\n",
    "\n",
    "print \"log_loss\", ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may look familiar to you.  This is almost exactly the formula for the [entropy of a discrete probability distribution](https://en.wikipedia.org/wiki/Entropy_%28information_theory%29).  The only difference is that the entropy uses a log with base 2 whereas the log loss typically uses the natural log.  This connection can give you some new ways to think about what this log loss really means.\n",
    "\n",
    "One interpretation is that the entropy gives us the number of bits of randomness in each event.  Therefore, a crime in San Francisco has $2.68 \\times \\frac{\\ln e}{\\ln 2} = 3.87$ bits of randomness associated with it.  Any improvements that you can glean from your model can be quantified by calculating the gain in information that your model provides expressed in bits.  For instance, the leading model on Kaggle right now has a log loss of 2.05 which translates to 2.95 bits of randomness.  The difference betweeen these two is .91 bits.\n",
    "\n",
    "Other ways to think about Entropy:\n",
    "1.  On average how surprised are you when an event occurs?\n",
    "2.  How much data would it take to encode a stream of events?  The inverse being, how much can you compress a stream of data given some underlying knowledge of its structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
